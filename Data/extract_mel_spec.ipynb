{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(audio_path, start_time=0, duration_sec=10):\n",
    "    wav, sr = librosa.load(audio_path, sr=22050)\n",
    "    \n",
    "    length = sr*duration_sec\n",
    "    y = np.zeros(length)\n",
    "    if wav.shape[0] < length:\n",
    "        y[:len(wav)] = wav\n",
    "    else:\n",
    "        y = wav[start_time:start_time+length]\n",
    "    \n",
    "    return y\n",
    "\n",
    "def get_spec_from_audio(audio_path, start_time=0, duration_sec=10):\n",
    "    y = get_audio(audio_path, start_time, duration_sec)\n",
    "    \n",
    "    window_size = 1024\n",
    "    window = np.hanning(window_size)\n",
    "    stft  = librosa.core.spectrum.stft(y, n_fft=window_size, hop_length=512, window=window)\n",
    "    out = 2 * np.abs(stft) / np.sum(window)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def get_sample_list(audio_path):\n",
    "    sample_nums = []\n",
    "    for f in os.listdir(audio_path):\n",
    "        if '.wav' in f:\n",
    "            sample_nums.append(f.strip('.wav'))\n",
    "    return sample_nums\n",
    "\n",
    "def save_spec(audio_path):\n",
    "    sample_nums = get_sample_list(audio_path)\n",
    "    for num in sample_nums:\n",
    "        spec = get_spec_from_audio(os.path.join(audio_path, num + '.wav'))\n",
    "        fig = plt.Figure()\n",
    "        canvas = FigureCanvas(fig)\n",
    "        ax = fig.add_subplot(111)\n",
    "        p = librosa.display.specshow(librosa.amplitude_to_db(spec, ref=np.max), ax=ax, y_axis='log', x_axis='time')\n",
    "        fig.savefig(os.path.join(audio_path, num + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_root = '/media/daftpunk2/home/yoonjin'\n",
    "exp_name = '2nd_inference_save_' + '200_800'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start save ...Someone_groan_in_the_background-000799e_799iter.pth\n",
      "Start save ...Person_whistle-000799e_799iter.pth\n",
      "Start save ...A_man_gives_a_speech-000799e_799iter.pth\n",
      "Start save ...Cat_is_whistling-000799e_799iter.pth\n",
      "Start save ...Someone_grunt_in_the_background-000799e_799iter.pth\n",
      "Start save ...A_chime_bell_rings_musically-000799e_799iter.pth\n",
      "Start save ...A_bell_sounds_loudly_and_then_fades_away-000799e_799iter.pth\n"
     ]
    }
   ],
   "source": [
    "for d in os.listdir(os.path.join(audio_root, exp_name)):\n",
    "    print('Start save ...' + d)\n",
    "    save_spec(os.path.join(audio_root, exp_name, d, 'interpolates'))\n",
    "    save_spec(os.path.join(audio_root, exp_name, d, 'optimized'))\n",
    "    save_spec(os.path.join(audio_root, exp_name, d, 'target'))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save ...A_man_gives_a_speech\n",
      "Save ...Cat_is_whistling\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ame_list.pk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fefba37af584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# fig.savefig(os.path.join(d, y_id + '.png'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0msoundfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22050\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCM_24'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ame_list.pk'"
     ]
    }
   ],
   "source": [
    "# 원본 데이터 spec 저장\n",
    "audio_path = '/media/daftpunk2/home/jakeoneijk/221008_audio_caps/audiocaps_audio_dataset/train'\n",
    "df = pd.read_csv(f'./train.csv')\n",
    "\n",
    "f_dict = {}\n",
    "\n",
    "for f in os.listdir(audio_path):\n",
    "    f_dict[f.split(']_')[0].strip('[')] = os.path.join(audio_path, f)\n",
    "\n",
    "# 프롬프트 y_id 뽑기 start time 찾기. 왤케 비효율적으로 코드 짜는걸까 나란 녀석...\n",
    "for d in os.listdir('./'):\n",
    "    if not os.path.isdir(d) or d == 'caps_full' or d == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    \n",
    "    if len(os.listdir(d)) == 6:\n",
    "        continue\n",
    "    \n",
    "    # if 'A_man' not in d:\n",
    "    #     continue\n",
    "    \n",
    "    print('Save ...' + d)\n",
    "    y_id = (os.listdir(os.path.join(d, 'test'))[1]).strip('_mel.npy')\n",
    "    start_time = df.loc[df['youtube_id'] == y_id]['start_time']\n",
    "    spec = get_spec_from_audio(f_dict[y_id], start_time=start_time)\n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = librosa.display.specshow(librosa.amplitude_to_db(spec, ref=np.max), ax=ax, y_axis='log', x_axis='time')\n",
    "    fig.savefig(os.path.join(d, y_id + '.png'))\n",
    "    \n",
    "    audio = get_audio(f_dict[y_id], start_time=start_time)\n",
    "    soundfile.write(os.path.join(d, y_id + '.wav'), audio, 22050, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) \n[GCC 9.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "57e44f573e1c79be2bf9ef7ab68f1d54b5bf5d8c47bf85e7907949da70fac8cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
